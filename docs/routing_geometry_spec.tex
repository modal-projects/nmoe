\documentclass[11pt]{article}

\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amssymb,amsthm,amsfonts,mathtools}
\usepackage{booktabs}
\usepackage{microtype}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage{tcolorbox}
\usepackage{listings}

\hypersetup{
  colorlinks=true,
  linkcolor=blue,
  urlcolor=cyan,
  pdftitle={Routing Geometry Specification for MoE Transformers},
}

% --- theorem-like spec environments (meta-spec style) ---
\newtheorem{definition}{Definition}
\newtheorem{axiom}{Axiom}
\newtheorem{property}{Property}
\newtheorem{verification}{Verification Test}
\newtheorem{proposition}{Proposition}
\newtheorem{requirement}{Requirement}

% --- notation helpers ---
\newcommand{\R}{\mathbb{R}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\norm}[1]{\left\lVert #1 \right\rVert}
\newcommand{\inner}[2]{\left\langle #1, #2 \right\rangle}
\newcommand{\RMS}{\mathrm{RMS}}

\title{Routing Geometry Specification for DeepSeek-Shaped MoE Transformers}
\author{Anonymous Authors}
\date{}

\begin{document}
\maketitle

\begin{abstract}
This document is a meta-spec style problem specification for \emph{routing geometry} in pre-norm Mixture-of-Experts (MoE) Transformers.
We define routing objects, margins, and sensitivity functionals under explicit gate semantics, then state verifiable properties (``laws'') together with conservative verification tests and artifact schemas.
The intent is to make routing-geometry claims \emph{unambiguous, falsifiable, and reproducible} before any intervention results.
\end{abstract}

\tableofcontents

\section{Scope and Non-Goals}

\paragraph{Scope.}
We specify (i) the routing objects induced by a fixed gate semantics, (ii) the geometry of routing boundaries under that semantics, and (iii) measurable stability/sensitivity properties of MoE layers under counterfactual perturbations.

\paragraph{Non-goals.}
This document does not prescribe training recipes, hyperparameters, or architectural interventions.
It specifies \emph{what is measured} and \emph{what must be true} for claims about routing geometry to be accepted as verified.

\section{Notation}

Let $d$ be hidden dimension and $E$ the number of routed experts at a layer.
Vectors are in $\R^d$ unless stated otherwise.
We write the per-token residual stream as $x\in\R^d$ and the MoE branch update as $u\in\R^d$.
Layer indices are $\ell\in\{0,\dots,L-1\}$.

\begin{definition}[RMS normalization]\label{def:rms}
For $\varepsilon>0$, define
\[
\RMS_\varepsilon(x) := \sqrt{\tfrac{1}{d}\sum_{i=1}^d x_i^2 + \varepsilon},
\qquad
z(x) := x / \RMS_\varepsilon(x).
\]
For RMSNorm with weight $\gamma\in\R^d$, define $y_\gamma(x) := \gamma \odot z(x)$.
\end{definition}

\section{Routing Objects and Boundary Quantities}

\begin{definition}[Exact gate rule]\label{def:gate_rule}
An \emph{exact gate rule} is a deterministic function $\mathrm{Gate}(\cdot)$ that maps a gate input $y\in\R^d$ to:
\begin{enumerate}
  \item selection scores $s(y)\in\R^{E}$, and
  \item a top-$k$ ordered list $\mathrm{TopK}_{k}(y)\in\{1,\dots,E\}^{k}$ (ties resolved deterministically),
\end{enumerate}
including any bias correction, group masking, scaling, and score nonlinearity required by the model family.
\end{definition}

\begin{definition}[Gate semantics profile]\label{def:gate_semantics}
A \emph{gate semantics profile} $\mathcal{S}$ is a versioned tuple specifying:
\begin{enumerate}
  \item Score computation: linear projection $W_g \in \R^{d \times E}$ plus optional bias $b_g$;
  \item Grouping/masking: expert groups $\{G_1,\dots,G_m\}$ with per-group top-$k_g$ selection;
  \item Tie-breaking: deterministic rule (e.g., lower index wins);
  \item Score dtype: fp32 (required by \cref{ax:fp32}).
\end{enumerate}
We denote the DeepSeek V3 semantics as $\mathcal{S}_{\mathrm{DSv3}}$: 256 routed experts, 8 groups of 32, top-1 per group $\to$ top-8 overall, sigmoid scoring, shared expert excluded from routing.
\end{definition}

\begin{definition}[Eligibility set]\label{def:eligible}
Fix a gate semantics profile $\mathcal{S}$.
For a gate input $y\in\R^d$, define the \emph{eligibility set} $\mathrm{Eligible}_\mathcal{S}(y)\subseteq\{1,\dots,E\}$ as the set of routed experts that are eligible for selection under $\mathcal{S}$ at $y$ (i.e., after applying any group constraints, masks, and shared-expert exclusions).
When $\mathcal{S}$ is clear from context we write $\mathrm{Eligible}(y)$.
\end{definition}

\begin{definition}[MoE layer set and terminal MoE layer]\label{def:terminal_moe}
Let $\mathcal{M}\subseteq\{0,\dots,L-1\}$ be the set of layers that implement a routed MoE (i.e., have an exact gate rule in \cref{def:gate_rule}).
Define the \emph{terminal MoE layer} as $\ell^\star := \max \mathcal{M}$ (when $\mathcal{M}$ is nonempty).
\end{definition}

\begin{definition}[Top-$k$ routing object]\label{def:topk_set}
Let $R_k(y)$ denote the \emph{unordered} top-$k$ set induced by the exact gate rule:
\[
R_k(y) := \{\mathrm{TopK}_{k}(y)_1,\dots,\mathrm{TopK}_{k}(y)_k\} \subseteq \{1,\dots,E\}.
\]
\end{definition}

\begin{definition}[$k$-th and $(k\!+\!1)$-th competitors]\label{def:kkp1}
Let $\mathrm{TopK}_{k+1}(y)\in\{1,\dots,E\}^{k+1}$ be the ordered top-$(k+1)$ list under the exact gate rule.
Define
\[
e_k(y) := \mathrm{TopK}_{k+1}(y)_{k},\qquad e_{k+1}(y) := \mathrm{TopK}_{k+1}(y)_{k+1}.
\]
\end{definition}

\begin{definition}[Set-margin and fixed-pair margin]\label{def:margins}
Let $s_{(i)}(y)$ denote the $i$-th largest selection score in $s(y)$ (post bias/masks; pre top-$k$ truncation).
Define:
\[
m_{\mathrm{set}}(y) := s_{(k)}(y) - s_{(k+1)}(y),
\qquad
m_{\mathrm{fixed}}(y) := s_{(1)}(y) - s_{(2)}(y).
\]
\end{definition}

\begin{definition}[Empirical quantile (order statistic)]\label{def:quantile}
Let $V=\{v_1,\dots,v_n\}$ be a finite multiset of real values and let $V_{\mathrm{fin}}:=\{v_i:\; v_i \text{ is finite}\}$ with $m:=|V_{\mathrm{fin}}|$.
If $m=0$, the quantile is undefined.
Otherwise, let $v_{(1)} \le \cdots \le v_{(m)}$ be the sorted finite values (ties allowed).
For $q\in[0,1]$, define $k(q):=\max(1,\min(m,\lceil qm\rceil))$ and
\[
\mathrm{Quantile}_q(V) := v_{(k(q))}.
\]
This is the left-continuous inverse empirical CDF; it is deterministic under ties.
\end{definition}

\begin{definition}[Decile bins (global)]\label{def:deciles}
Fix a layer $\ell$ and a finite evaluation sample of tokens with associated margins $\{m_t\}$.
Define the decile edges
\[
e_i := \mathrm{Quantile}_{i/10}(\{m_t\}) \quad \text{for } i\in\{0,\dots,10\}.
\]
The $i$-th decile bin is the token set
\[
\mathrm{Decile}_i := \{t:\; e_{i-1}\le m_t < e_i\} \quad \text{for } i\in\{1,\dots,9\},
\qquad
\mathrm{Decile}_{10} := \{t:\; e_9\le m_t \le e_{10}\}.
\]
Bins may be empty under ties; any monotonicity check must ignore empty bins.
\end{definition}

\begin{definition}[Set overlap functional]\label{def:ovk}
For two gate inputs $y,y'\in\R^d$, define top-$k$ set overlap:
\[
\mathrm{ov}_k(y,y') := \frac{|R_k(y)\cap R_k(y')|}{k}\in[0,1].
\]
Define disagreement mass $d(y,y') := 1-\mathrm{ov}_k(y,y')$.
\end{definition}

\begin{definition}[Swap functional]\label{def:swapk}
For two gate inputs $y,y'\in\R^d$, define
\[
\mathrm{swap}_k(y,y') := \mathbf{1}\left[e_k(y)\ne e_k(y')\right].
\]
\end{definition}

\section{Counterfactual Sensitivity Functionals}

\begin{definition}[Counterfactual re-gating functional]\label{def:counterfactual}
In a pre-norm MoE block, let $x_{\mathrm{pre}}$ be the residual stream immediately before the MoE branch and let the gate read
$y_{\mathrm{pre}} := y_\gamma(x_{\mathrm{pre}})$.
Let the branch output be $u := \mathrm{MoE}(y_{\mathrm{pre}})$ (under the model's actual routing).
Define the counterfactual post-update gate input
$y_{\mathrm{post}} := y_\gamma(x_{\mathrm{pre}}+u)$.
The \emph{counterfactual re-gating overlap} is
\[
\mathrm{ov}_k^{\mathrm{cf}} := \mathrm{ov}_k(y_{\mathrm{pre}},y_{\mathrm{post}}).
\]
\end{definition}

\begin{axiom}[Score precision]\label{ax:fp32}
All selection-score computations used for $R_k(\cdot)$, $m_{\mathrm{set}}(\cdot)$, and $m_{\mathrm{fixed}}(\cdot)$ are performed in fp32.
This avoids tie-collapse artifacts from bf16 score quantization and is required for a well-defined ``boundary tail''.
\end{axiom}

\begin{axiom}[Counterfactual semantics]\label{ax:counterfactual_semantics}
The counterfactual input $y_{\mathrm{post}}$ in \cref{def:counterfactual} is a \emph{sensitivity functional}, not an assertion about the forward path:
in pre-norm models, the router is not re-evaluated on $y_{\mathrm{post}}$ in the same layer.
\end{axiom}

\section{KL-Bounded Adaptation Framework}\label{sec:kl_framework}

This section formalizes the relationship between KL drift from a base model and base-domain performance regression (a forgetting proxy).
It is written to be compatible with ``KL-as-a-predictor'' frameworks (e.g., RL's Razor, arXiv:2509.04259) while remaining self-contained:
all properties below are verified from our own artifacts under explicit measurement semantics.

\begin{definition}[Teacher-forced next-token distribution]\label{def:tf_next_token}
Let $w=(x_1,\dots,x_{T+1})$ be a token window.
For parameters $\theta$, define the teacher-forced next-token distribution at position $t\in\{1,\dots,T\}$ as
\[
p_\theta(\cdot \mid x_{\le t}) := \mathrm{softmax}(\mathrm{logits}_\theta(x_{\le t}))\in\Delta^{V-1},
\]
where $V$ is the vocabulary size and $\Delta^{V-1}$ is the probability simplex.
\end{definition}

\begin{definition}[Per-window KL drift]\label{def:window_kl}
Fix base parameters $\theta_0$ and comparison parameters $\theta$.
For a token window $w=(x_1,\dots,x_{T+1})$, define the per-window forward KL drift (averaged over next-token positions):
\[
D(w;\theta,\theta_0)
:=
\frac{1}{T}\sum_{t=1}^{T}
D_{\mathrm{KL}}\!\left(p_\theta(\cdot\mid x_{\le t}) \,\|\, p_{\theta_0}(\cdot\mid x_{\le t})\right).
\]
\end{definition}

\begin{definition}[Frozen layer set]\label{def:frozen_set}
A \emph{frozen layer set} $\mathcal{F} \subseteq \{0, \ldots, L-1\}$ is a subset of layers whose parameters are held fixed during fine-tuning:
\[
\theta_\ell = \theta_{0,\ell} \quad \forall \ell \in \mathcal{F}.
\]
The \emph{trainable set} is $\mathcal{T} := \{0, \ldots, L-1\} \setminus \mathcal{F}$.
\end{definition}

\begin{definition}[Forgetting metric]\label{def:forgetting}
For a held-out evaluation distribution $\mathcal{D}_{\mathrm{base}}$ representing base-domain capabilities, define the \emph{forgetting proxy}:
\[
\mathcal{L}_{\mathrm{forget}}(\theta) := \E_{x \sim \mathcal{D}_{\mathrm{base}}}\bigl[\mathrm{loss}_\theta(x) - \mathrm{loss}_{\theta_0}(x)\bigr],
\]
where $\mathrm{loss}_\theta(x)$ is the cross-entropy loss on sample $x$.
\end{definition}

\begin{definition}[Mean KL drift]\label{def:mean_kl}
For an evaluation distribution $\mathcal{D}_{\mathrm{eval}}$ over windows, define the mean KL drift:
\[
\bar{D}(\theta, \theta_0) := \E_{w \sim \mathcal{D}_{\mathrm{eval}}}[D(w; \theta, \theta_0)].
\]
\end{definition}

\begin{proposition}[Frozen layers preserve distributions (definitional)]\label{prop:frozen_kl}
If all layers are frozen ($\mathcal{F} = \{0, \ldots, L-1\}$), then $\theta = \theta_0$ and hence $D(x; \theta, \theta_0) = 0$ for all $x$.
More generally, freezing more layers constrains the achievable KL divergence.
\end{proposition}

\begin{proof}
By \cref{def:frozen_set}, $\theta_\ell = \theta_{0,\ell}$ for all $\ell \in \mathcal{F}$.
If $\mathcal{F} = \{0, \ldots, L-1\}$, then $\theta = \theta_0$, so $p_\theta(\cdot | x) = p_{\theta_0}(\cdot | x)$ and $D_{\mathrm{KL}} = 0$.
\end{proof}

\section{Propositions (math baselines)}

\begin{proposition}[Random-set overlap baseline]\label{prop:random_overlap}
Let $A,B\subseteq\{1,\dots,E\}$ be independent uniformly random size-$k$ subsets (ignoring ordering).
Then $\E[|A\cap B|]=k^2/E$ and $\E[\mathrm{ov}_k]=k/E$.
\end{proposition}

\begin{proof}
For each $i\in A$, $\Pr[i\in B]=k/E$, so $\E[|A\cap B|]=\sum_{i\in A}\Pr[i\in B]=k\cdot (k/E)$.
\end{proof}

\paragraph{Null validity under grouping.}
The $k/E$ random baseline assumes uniform i.i.d.\ selection.
Under grouped routing (e.g., DeepSeek's 8 groups of 32), the effective null is $\sum_g k_g / |G_g|$ where $k_g$ is per-group top-$k$.
Verification tests must either (a) compute the family-specific null from $\mathcal{S}$, or (b) use empirical nulls (random-expert substitution, within-window permutation).

\section{Bootstrap Protocol}\label{sec:bootstrap}

All confidence intervals are computed via non-parametric bootstrap over windows:
\begin{enumerate}
  \item \textbf{Resampling unit:} windows (not tokens), to preserve within-window correlation.
  \item \textbf{Replicates:} $B \geq 200$ (record exact $B$ in artifact).
  \item \textbf{CI type:} percentile method (2.5\%, 97.5\%) unless BCa is specified.
  \item \textbf{Seed:} deterministic, recorded in artifact for reproducibility.
  \item \textbf{Derived statistics:} derived quantities must be computed from stored per-window arrays. For ``max adjacent jump,'' re-compute $\arg\min$ per bootstrap replicate (not fixed to the observed $\arg\min$).
\end{enumerate}

\section{Properties (claims that must be verified)}

We fix a significance level $\alpha = 0.05$ throughout.
For a statistic $\theta$, let $\mathrm{CI}_{1-\alpha}(\theta) = [\theta_{\mathrm{lo}}, \theta_{\mathrm{hi}}]$ denote the $(1-\alpha)$ bootstrap confidence interval computed per \cref{sec:bootstrap}.

\begin{property}[Boundary amplification]\label{prop:boundary_amp}
Fix a layer $\ell \in \mathcal{M}$, a checkpoint edge $(a,b)$ within a model family, a domain distribution $\mathcal{D}$ over gate inputs at layer $\ell$, and a \emph{reference checkpoint} $r \in \{a,b\}$ that defines the set-margin stratification (recorded as the artifact \texttt{edge.direction}).
For token $t$ with gate input $y_t$, let $R_k^{(a)}(y_t)$ and $R_k^{(b)}(y_t)$ denote the top-$k$ sets under checkpoints $a$ and $b$ evaluated on the \emph{same} $y_t$ (under the same gate semantics profile).
Define disagreement mass
\[
d_t := 1 - \frac{|R_k^{(a)}(y_t)\cap R_k^{(b)}(y_t)|}{k}.
\]
Fix $q \in (0,1)$. For each sampled window $w$, define the window-conditional set-margin threshold
\[
Q_q(w) := \mathrm{Quantile}_q(\{m_{\mathrm{set}}^{(r)}(y_t) : t \in w\}),
\]
and define the \emph{window compression}:
\[
F_w(q) :=
\begin{cases}
\frac{\sum_{t\in w:\, m_{\mathrm{set}}^{(r)}(y_t) \leq Q_q(w)} d_t}{\sum_{t\in w} d_t}, & \sum_{t\in w} d_t > 0,\\
0, & \sum_{t\in w} d_t = 0.
\end{cases}
\]
Define the \emph{compression functional} as the window expectation $F(q) := \E_w[F_w(q)]$.
Define the \emph{effective baseline fraction} for next-token aligned windows of length $T$ as:
\[
q_{\mathrm{eff}}(q;T) := \frac{\lceil qT \rceil}{T}.
\]
In this document, $T=\texttt{data.seq\_len}-1$ for all next-token aligned probes.

The property \textbf{holds} if and only if both conditions are satisfied:
\begin{enumerate}
  \item \textbf{(Concentration)} $\exists\, q_0 \in \{0.01, 0.05, 0.10, 0.20\}$ such that
  \[
  \inf \mathrm{CI}_{1-\alpha}(F(q_0) - q_{\mathrm{eff}}(q_0;T)) > 0.
  \]
  \item \textbf{(Monotonicity)} Let $\mathrm{Decile}_i$ be the global decile bins of $\{m_{\mathrm{set}}^{(r)}(y_t)\}$ (over the evaluation sample) per \cref{def:deciles}.
  For each non-empty bin, define $\bar{d}(i) := \E[d_t \mid t \in \mathrm{Decile}_i]$.
  Then $\bar{d}(1) \geq \bar{d}(2) \geq \cdots \geq \bar{d}(10)$ for all $i$ with $|\mathrm{Decile}_i|>0$.
\end{enumerate}
\end{property}

\begin{property}[Behavioral compression (diagnostic negative control)]\label{prop:behavior_compression}
Fix the same setup as \cref{prop:boundary_amp}, inheriting the reference checkpoint $r \in \{a,b\}$ and set-margin stratification.
For a raw-text window $w$ with tokens $(x_1,\dots,x_T)$, define the per-token teacher-forced behavioral mass
\[
b_t := \big|\log p_a(x_{t+1}\mid x_{\le t})-\log p_b(x_{t+1}\mid x_{\le t})\big|.
\]
Define the window-conditional set-margin threshold $Q_q(w)$ from the reference checkpoint $r$ as in \cref{prop:boundary_amp}, and define behavioral compression:
\[
F_w^{\mathrm{beh}}(q) :=
\begin{cases}
\frac{\sum_{t\in w:\, m_{\mathrm{set}}^{(r)}(y_t) \leq Q_q(w)} b_t}{\sum_{t\in w} b_t}, & \sum_{t\in w} b_t > 0,\\
0, & \sum_{t\in w} b_t = 0.
\end{cases}
\]
Let $F^{\mathrm{beh}}(q) := \E_w[F_w^{\mathrm{beh}}(q)]$.

The diagnostic \textbf{holds} if and only if for all $q \in \{0.01,0.05,0.10,0.20\}$:
\[
\inf \mathrm{CI}_{1-\alpha}\bigl(F^{\mathrm{beh}}(q) - q_{\mathrm{eff}}(q;T)\bigr) \le 0.
\]
Equivalently, behavioral change is not significantly more boundary-supported than the uniform baseline under the routing boundary stratification.
\end{property}

\begin{property}[Set-boundary chart redundancy]\label{prop:overlap_compat}
Fix a layer $\ell \in \mathcal{M}$ and domain distribution $\mathcal{D}$.
For token $t$ with gate input $y_t$, let $(e_k, e_{k+1})$ be the $k$-th and $(k\!+\!1)$-th competitors (\cref{def:kkp1}) under the exact gate rule, and let $m_{\mathrm{set}}(y_t)$ be the set-margin.
Let $\mathrm{Eligible}(y_t)$ be the eligibility set under the gate semantics profile (\cref{def:eligible}).
Let $e_{\mathrm{rand}} \sim \mathrm{Uniform}(\mathrm{Eligible}(y_t)\setminus\{e_k,e_{k+1}\})$.

Let $u_e(y_t)$ denote the routed expert output for expert $e$ evaluated on the \emph{same} $y_t$ (no gating weights; shared experts excluded).
Let $w_{y_{t+1}}$ denote the unembedding row for the teacher-forced next token id.
Define the (bounded) redundancy indices:
\[
\kappa_{\mathrm{hidden}}(t)
:=\frac{\|u_{e_k}(y_t)-u_{e_{k+1}}(y_t)\|}{\|u_{e_k}(y_t)\|+\|u_{e_{k+1}}(y_t)\|+\epsilon},
\quad
\kappa_{\mathrm{target}}(t)
:=\frac{|w_{y_{t+1}}^\top u_{e_k}(y_t)-w_{y_{t+1}}^\top u_{e_{k+1}}(y_t)|}{|w_{y_{t+1}}^\top u_{e_k}(y_t)|+|w_{y_{t+1}}^\top u_{e_{k+1}}(y_t)|+\epsilon}.
\]
Define random-competitor analogues $\kappa_{\mathrm{hidden}}^{\mathrm{rand}}(t)$ and $\kappa_{\mathrm{target}}^{\mathrm{rand}}(t)$ by replacing $e_{k+1}$ with $e_{\mathrm{rand}}$.

Fix boundary quantile $q_b = 0.10$ and interior quantile $q_i = 0.50$.%
\footnote{The symmetric design $q_i = 0.90$ (comparing extreme boundary to extreme interior) is more rigorous and should be used if the property passes under that stricter test. The current $q_i = 0.50$ aligns with existing measurements and provides greater statistical power.}
For each sampled window $w$, define window-conditional strata:
\[
\mathcal{B}(w) := \{t \in w : m_{\mathrm{set}}(y_t) \leq \mathrm{Quantile}_{q_b}(m_{\mathrm{set}}|w)\}, \quad
\mathcal{I}(w) := \{t \in w : m_{\mathrm{set}}(y_t) \geq \mathrm{Quantile}_{q_i}(m_{\mathrm{set}}|w)\}.
\]
Let $\widetilde{\kappa}(w,\mathcal{B})$ denote the per-window median of $\kappa(t)$ over $t\in\mathcal{B}(w)$, and similarly for $\mathcal{I}$ and for $\kappa^{\mathrm{rand}}$.

Define the two V2 axes (hidden-space) for a fixed layer $\ell$ as the window-level median differences:
\[
\Delta_{\mathrm{BI}}(w;\ell) := \widetilde{\kappa}_{\mathrm{hidden}}(w,\mathcal{B})-\widetilde{\kappa}_{\mathrm{hidden}}(w,\mathcal{I}),\qquad
\Delta_{\mathrm{Brand}}(w;\ell) := \widetilde{\kappa}_{\mathrm{hidden}}(w,\mathcal{B})-\widetilde{\kappa}_{\mathrm{hidden}}^{\mathrm{rand}}(w,\mathcal{B}).
\]

The property \textbf{holds} for a layer $\ell$ (hidden-space redundancy) if and only if both axes satisfy:
\begin{enumerate}
  \item \textbf{(C1: boundary vs interior)} $\sup \mathrm{CI}_{1-\alpha}\bigl(\Delta_{\mathrm{BI}}(w;\ell)\bigr) < 0$.
  \item \textbf{(C2: adjacency specificity / random-e2 kill-shot)} $\sup \mathrm{CI}_{1-\alpha}\bigl(\Delta_{\mathrm{Brand}}(w;\ell)\bigr) < 0$.
\end{enumerate}
\end{property}

\begin{property}[Set-boundary target redundancy (diagnostic)]\label{prop:overlap_compat_target}
Under the same setup as \cref{prop:overlap_compat}, define $\kappa_{\mathrm{target}}(t)$ and $\kappa_{\mathrm{target}}^{\mathrm{rand}}(t)$.
Define the two diagnostic target-space axes for a fixed layer $\ell$ as the window-level median differences:
\[
\Delta_{\mathrm{BI}}^{\mathrm{target}}(w;\ell) := \widetilde{\kappa}_{\mathrm{target}}(w,\mathcal{B})-\widetilde{\kappa}_{\mathrm{target}}(w,\mathcal{I}),\qquad
\Delta_{\mathrm{Brand}}^{\mathrm{target}}(w;\ell) := \widetilde{\kappa}_{\mathrm{target}}(w,\mathcal{B})-\widetilde{\kappa}_{\mathrm{target}}^{\mathrm{rand}}(w,\mathcal{B}).
\]
The property \textbf{holds} for a layer $\ell$ if and only if:
\begin{enumerate}
  \item \textbf{(C1: boundary vs interior)} $\sup \mathrm{CI}_{1-\alpha}\bigl(\Delta_{\mathrm{BI}}^{\mathrm{target}}(w;\ell)\bigr) < 0$.
  \item \textbf{(C2: adjacency specificity / random-e2 kill-shot)} $\sup \mathrm{CI}_{1-\alpha}\bigl(\Delta_{\mathrm{Brand}}^{\mathrm{target}}(w;\ell)\bigr) < 0$.
\end{enumerate}
\end{property}

\begin{property}[Terminal interface regime]\label{prop:terminal_regime}
Fix a checkpoint, domain distribution $\mathcal{D}$, and measurement set $\mathcal{L} \subseteq \mathcal{M}$ with $\ell^\star \in \mathcal{L}$.
For each layer $\ell \in \mathcal{L}$, define the mean counterfactual overlap:
\[
\bar{o}(\ell) := \E_{t \sim \mathcal{D}}[\mathrm{ov}_k^{\mathrm{cf}}(t, \ell)].
\]
For consecutive layers $\ell_1 < \ell_2$ in $\mathcal{L}$, define the \emph{adjacent jump}:
\[
\Delta(\ell_1 \to \ell_2) := \bar{o}(\ell_2) - \bar{o}(\ell_1).
\]
Let $(\ell^\star_{\mathrm{prev}}, \ell^\star)$ be the terminal adjacent pair, where $\ell^\star_{\mathrm{prev}} := \max\{\ell \in \mathcal{L} : \ell < \ell^\star\}$.

The property \textbf{holds} if and only if both conditions are satisfied:
\begin{enumerate}
  \item \textbf{(Significant drop)}
  \[
  \sup \mathrm{CI}_{1-\alpha}\bigl(\Delta(\ell^\star_{\mathrm{prev}} \to \ell^\star)\bigr) < 0.
  \]
  \item \textbf{(Dominance; meta-spec strong)} Let $\widehat{\mathrm{cliff}}$ be the bootstrap-defined cliff location:
  for each bootstrap replicate, re-compute $\bar{o}(\ell)$ and $\arg\min_{(\ell_1,\ell_2)} \Delta(\ell_1 \to \ell_2)$ from the resampled windows, yielding $\widehat{\mathrm{cliff}}^{(b)}$.
  The property requires:
  \[
  \Pr_{b\sim\text{bootstrap}}[\widehat{\mathrm{cliff}}^{(b)} = (\ell^\star_{\mathrm{prev}}, \ell^\star)] \ge 0.95.
  \]
\end{enumerate}
\end{property}

\begin{property}[Terminal tracking (cross-model)]\label{prop:terminal_tracking}
Fix a finite set of models $\{\mathcal{M}_j\}_{j=1}^{J}$, where model $\mathcal{M}_j$ has a terminal MoE layer $\ell^\star_j$.
For each $\mathcal{M}_j$, fix a domain distribution $\mathcal{D}_j$ and a measurement set $\mathcal{L}_j \subseteq \mathcal{M}_j$ with $\ell^\star_j \in \mathcal{L}_j$.
Let $A_j$ be the V3 artifact (\texttt{terminal\_ovk\_scan}) for $\mathcal{M}_j$ on $\mathcal{D}_j$.

The property \textbf{holds} if and only if:
\begin{enumerate}
  \item \textbf{(Per-model terminal localization)} For every $j$, $A_j$ satisfies \cref{prop:terminal_regime} with terminal layer $\ell^\star_j$ recorded in the artifact.
  \item \textbf{(Non-degeneracy)} There exist $j \ne j'$ such that $\ell^\star_j \ne \ell^\star_{j'}$ (at least two distinct terminal depths).
\end{enumerate}

\paragraph{Note (stronger falsifier).}
A within-family intervention that \emph{moves} the terminal MoE position by architectural modification and retraining is a stronger causal discriminator, but is not required for this cross-model property.
\end{property}

\begin{property}[KL-bounded adaptation via structural freeze]\label{prop:kl_bounded}
Let $\theta_0$ be a base model and $\theta$ a fine-tuned model obtained via a training recipe with frozen layer set $\mathcal{F}$ (\cref{def:frozen_set}).
Let $\mathcal{D}_{\mathrm{eval}}$ be an evaluation distribution and $\mathcal{D}_{\mathrm{base}}$ a held-out distribution for forgetting measurement.

Define the empirical quantities:
\[
\hat{D} := \frac{1}{N}\sum_{i=1}^{N} D(x_i; \theta, \theta_0), \quad
\hat{\mathcal{L}}_{\mathrm{forget}} := \frac{1}{M}\sum_{j=1}^{M} \bigl[\mathrm{loss}_\theta(x_j) - \mathrm{loss}_{\theta_0}(x_j)\bigr],
\]
where $\{x_i\}_{i=1}^N \sim \mathcal{D}_{\mathrm{eval}}$ and $\{x_j\}_{j=1}^M \sim \mathcal{D}_{\mathrm{base}}$.

The property \textbf{holds} if and only if all conditions are satisfied:
\begin{enumerate}
  \item \textbf{(KL is bounded)} $\hat{D} \leq D_{\mathrm{max}}$ for a pre-registered threshold $D_{\mathrm{max}} > 0$.
  \item \textbf{(Forgetting is bounded)} $\hat{\mathcal{L}}_{\mathrm{forget}} \leq \mathcal{L}_{\mathrm{max}}$ for a pre-registered threshold $\mathcal{L}_{\mathrm{max}} > 0$.
  \item \textbf{(KL-forgetting correlation)} Across multiple checkpoints or training runs, the Spearman correlation $\rho(\hat{D}, \hat{\mathcal{L}}_{\mathrm{forget}}) > 0$ with
  \[
  \inf \mathrm{CI}_{1-\alpha}(\rho) > 0.
  \]
  \item \textbf{(Freeze advantage)} For a comparison model $\theta'$ trained with $\mathcal{F}' \subsetneq \mathcal{F}$ (fewer frozen layers) or $\mathcal{F}' = \emptyset$ (full fine-tune):
  \[
  \hat{D}(\theta) < \hat{D}(\theta') \quad \text{and} \quad \hat{\mathcal{L}}_{\mathrm{forget}}(\theta) < \hat{\mathcal{L}}_{\mathrm{forget}}(\theta').
  \]
\end{enumerate}

\paragraph{Independence from external claims.}
This property does not assume any external result (e.g., ``RL's Razor'').
The KL-forgetting correlation is established empirically on our own measurements.
If external work arrives at similar conclusions, this constitutes independent corroboration.
\end{property}

\begin{property}[KL-forgetting edge dominance (open-weights, RL Razor-aligned)]\label{prop:kl_edge_dominance}
Fix a \emph{family} consisting of a base checkpoint $\theta_0$ and a finite set of descendant checkpoints $\Theta=\{\theta_1,\dots,\theta_K\}$ claimed to share the same pretraining regime.
Fix a domain set $\mathfrak{D}$ of base-domain evaluation distributions.
In this document, the \emph{canonical V5-now domain set} is $\mathfrak{D}=\{\texttt{fineweb},\texttt{code}\}$, represented by fixed window samplers.

For each domain $d\in\mathfrak{D}$, define empirical per-window arrays on $n\ge 200$ windows:
\[
\widehat{D}_d(\theta_j) := \frac{1}{n}\sum_{i=1}^{n} D(w_i;\theta_j,\theta_0),
\qquad
\widehat{\mathcal{L}}_{\mathrm{forget},d}(\theta_j) := \frac{1}{n}\sum_{i=1}^{n}\bigl[\mathrm{loss}_{\theta_j}(w_i) - \mathrm{loss}_{\theta_0}(w_i)\bigr],
\]
where $w_i\sim \mathcal{D}_d$ are next-token windows and $D(w;\cdot,\cdot)$ is the forward KL drift in \cref{def:window_kl}.

Fix a pre-registered set of directed \emph{edges} $\mathcal{E}\subseteq\{1,\dots,K\}\times\{1,\dots,K\}$, where $(i,j)\in\mathcal{E}$ asserts that $\theta_j$ is ``more tuned'' than $\theta_i$ within the same family.

The property \textbf{holds} if and only if for every domain $d\in\mathfrak{D}$ and every edge $(i,j)\in\mathcal{E}$, both inequalities are satisfied:
\begin{enumerate}
  \item \textbf{(Drift dominance)} $\inf \mathrm{CI}_{1-\alpha}\!\left(\widehat{D}_d(\theta_j)-\widehat{D}_d(\theta_i)\right) > 0$.
  \item \textbf{(Forgetting dominance)} $\inf \mathrm{CI}_{1-\alpha}\!\left(\widehat{\mathcal{L}}_{\mathrm{forget},d}(\theta_j)-\widehat{\mathcal{L}}_{\mathrm{forget},d}(\theta_i)\right) > 0$.
\end{enumerate}

\paragraph{Interpretation (explicitly non-causal).}
Passing \cref{prop:kl_edge_dominance} establishes a monotone relationship between KL drift from base and base-domain regression \emph{across pre-registered edges} on fixed domains.
It does not, by itself, establish that KL drift \emph{causes} forgetting; that requires an intervention (e.g., V5b in \cref{prop:kl_bounded}).
\end{property}

\section{Verification Tests and Traceability}

\begin{verification}[V1: Boundary amplification]\label{vrf:boundary_amp}
\textbf{Goal:} Verify \cref{prop:boundary_amp}.

\textbf{Evaluation layer set.}
Fix a pre-registered required layer set $\mathcal{L}_{\mathrm{V1}} \subseteq \mathcal{M}$ recorded in the artifact (e.g., a mid-band set).

\textbf{Method:}
\begin{enumerate}
  \item Fix a checkpoint edge $(a,b)$ and a reference direction $r\in\{a,b\}$ (recorded in the artifact as \texttt{edge.direction}).
  \item Sample $n \geq 200$ windows from domain $\mathcal{D}$.
  \item For each token $t$, compute $d_t$ and $m_{\mathrm{set}}^{(r)}(y_t)$ under exact gate semantics (fp32).
  \item For each window $w$, compute $F_w(q)$ for $q \in \{0.01, 0.05, 0.10, 0.20\}$ using window-conditional set-margin quantiles.
  \item Compute per-decile means $\bar{d}(1), \dots, \bar{d}(10)$ using global decile bins per \cref{def:deciles}.
  \item Bootstrap over windows to obtain $\mathrm{CI}_{0.95}(F(q) - q)$ where $F(q)=\E_w[F_w(q)]$.
\end{enumerate}

\textbf{Pass criteria:}
\begin{enumerate}
  \item For each $\ell \in \mathcal{L}_{\mathrm{V1}}$ reported in the artifact, $\exists\, q_0 \in \{0.01,0.05,0.10,0.20\}$ such that $\inf \mathrm{CI}_{0.95}(F_\ell(q_0) - q_{\mathrm{eff}}(q_0;T)) > 0$.
  \item For each $\ell \in \mathcal{L}_{\mathrm{V1}}$, $\bar{d}_\ell(1) \geq \bar{d}_\ell(2) \geq \cdots \geq \bar{d}_\ell(10)$ (ignoring empty deciles).
\end{enumerate}

\textbf{Implementation:} \texttt{scripts/traj\_boundary\_amplification\_ondist\_topk.py}\\
\textbf{Artifact:} JSON containing per-window compression arrays and summary CI95 for $F_\ell(q)-q$, plus decile curves, and explicit \texttt{verification.required\_layers} and \texttt{edge.direction}.
\end{verification}

\begin{verification}[V1b: Behavioral compression (diagnostic)]\label{vrf:behavior_compression}
\textbf{Goal:} Report \cref{prop:behavior_compression} under the same set-margin stratification used for V1.

\textbf{Method:}
\begin{enumerate}
  \item Fix a checkpoint edge $(a,b)$ and a reference direction $r\in\{a,b\}$ (recorded in the artifact as \texttt{edge.direction}).
  \item Sample $n \geq 200$ raw-text windows from domain $\mathcal{D}$.
  \item For each token $t$, compute the set-margin $m_{\mathrm{set}}^{(r)}(y_t)$ (fp32 exact gate scoring) and the behavioral mass $b_t = |\log p_a(x_{t+1}\mid x_{\le t})-\log p_b(x_{t+1}\mid x_{\le t})|$ under teacher forcing.
  \item For each window $w$, compute $F_w^{\mathrm{beh}}(q)$ for $q \in \{0.01,0.05,0.10,0.20\}$ using window-conditional set-margin quantiles, then bootstrap over windows to obtain CI95 for $F^{\mathrm{beh}}(q)-q$.
\end{enumerate}

\textbf{Pass criteria (diagnostic):}
\begin{enumerate}
  \item For all $q \in \{0.01,0.05,0.10,0.20\}$, $\inf \mathrm{CI}_{0.95}(F^{\mathrm{beh}}(q)-q_{\mathrm{eff}}(q;T)) \le 0$ (no significant behavioral boundary amplification).
\end{enumerate}

\textbf{Implementation:} \texttt{scripts/traj\_behavior\_compression\_ondist\_topk.py}\\
\textbf{Artifact:} JSON per \texttt{docs/routing\_geometry\_artifacts.tex} (stores per-window $F_{\mathrm{route}}$ and $F_{\mathrm{beh}}$ arrays).
\end{verification}

\begin{verification}[V2: Set-boundary chart redundancy]\label{vrf:chart_compat}
\textbf{Goal:} Verify \cref{prop:overlap_compat} (required), and report \cref{prop:overlap_compat_target} (diagnostic).

\textbf{Evaluation layer set.}
Fix a pre-registered required layer set $\mathcal{L}_{\mathrm{V2}} \subseteq \mathcal{M}$ recorded in the artifact (e.g., a mid-band set or a terminal-only set).

\textbf{Method:}
\begin{enumerate}
  \item Sample $n \geq 200$ windows from domain $\mathcal{D}$.
  \item For each token $t$, compute $(e_k, e_{k+1})$ under exact gate semantics (fp32 scores), sample $e_{\mathrm{rand}}$, and compute $\kappa_{\mathrm{hidden}}(t)$ and $\kappa_{\mathrm{target}}(t)$ (and random-e2 analogues).
  \item For each window $w$, partition tokens by within-window set-margin quantiles into $\mathcal{B}(w)$ (bottom 10\%) and $\mathcal{I}(w)$ (top 50\%).
  \item Compute per-window medians $\widetilde{\kappa}(w,\mathcal{B})$, $\widetilde{\kappa}(w,\mathcal{I})$ and corresponding random-e2 medians.
  \item Bootstrap over windows to obtain CIs.
\end{enumerate}

\textbf{Pass criteria:}
\begin{enumerate}
  \item \textbf{(C1: boundary vs interior)} For each $\ell \in \mathcal{L}_{\mathrm{V2}}$ reported in the artifact, the CI95 upper bound of $\widetilde{\kappa}_{\mathrm{hidden}}(w,\mathcal{B})-\widetilde{\kappa}_{\mathrm{hidden}}(w,\mathcal{I})$ is below zero.
  \item \textbf{(C2: adjacency specificity / random-e2 kill-shot)} For each $\ell \in \mathcal{L}_{\mathrm{V2}}$, the CI95 upper bound of $\widetilde{\kappa}_{\mathrm{hidden}}(w,\mathcal{B})-\widetilde{\kappa}_{\mathrm{hidden}}^{\mathrm{rand}}(w,\mathcal{B})$ is below zero.
\end{enumerate}

\textbf{Reporting (data-only).}
For each required layer $\ell$, report the V2 failure type as one of:
\texttt{C1\_only}, \texttt{C2\_only}, \texttt{both}, \texttt{neither}, where \texttt{neither} denotes that both C1 and C2 pass at $\ell$.

\textbf{Implementation:} \texttt{scripts/testB\_chart\_compatibility.py}\\
\textbf{Artifact:} JSON emitted by \texttt{testB\_chart\_compatibility.py} with \texttt{strata\_def.margin\_used="m\_set"} and \texttt{strata\_def.pair\_def="k\_kp1"}, and with explicit \texttt{verification.required\_layers} and \texttt{summary.bootstrap=\{B,seed\}}; the artifact must store per-window medians so the pass/fail criteria are independently re-bootstrappable.
\end{verification}

\begin{verification}[V3: Terminal cliff depth scan]\label{vrf:terminal_scan}
\textbf{Goal:} Verify \cref{prop:terminal_regime}.

\textbf{Method:}
\begin{enumerate}
  \item Fix measurement set $\mathcal{L} \subseteq \mathcal{M}$ with $\ell^\star \in \mathcal{L}$ (e.g., $\{10, 20, 30, 40, 50, 59, 60\}$).
  \item Sample $n \geq 200$ windows from domain $\mathcal{D}$.
  \item For each $\ell \in \mathcal{L}$, compute $\bar{o}(\ell) = \E[\mathrm{ov}_k^{\mathrm{cf}}(t, \ell)]$.
  \item Compute all adjacent jumps $\Delta(\ell_1 \to \ell_2)$.
  \item Bootstrap over windows to obtain $\mathrm{CI}_{0.95}(\Delta(\ell^\star_{\mathrm{prev}} \to \ell^\star))$ and to estimate $\Pr[\widehat{\mathrm{cliff}}^{(b)}=(\ell^\star_{\mathrm{prev}},\ell^\star)]$ by re-computing $\arg\min$ per replicate.
\end{enumerate}

\textbf{Pass criteria:}
\begin{enumerate}
  \item $\sup \mathrm{CI}_{0.95}\bigl(\Delta(\ell^\star_{\mathrm{prev}} \to \ell^\star)\bigr) < 0$.
  \item $\Pr_{b\sim\text{bootstrap}}[\widehat{\mathrm{cliff}}^{(b)} = (\ell^\star_{\mathrm{prev}}, \ell^\star)] \ge 0.95$.
\end{enumerate}

\textbf{Implementation:} \texttt{scripts/testC\_terminal\_ovk\_scan.py}\\
\textbf{Artifact:} JSON with \texttt{per\_window.ovk\_cf\_mean}, \texttt{per\_window.swap\_k\_mean}, and \texttt{summary.max\_jump} (pair, delta\_mean, CI95).
\end{verification}

\begin{verification}[V4: Terminal tracking (cross-model)]\label{vrf:terminal_tracking}
\textbf{Goal:} Verify \cref{prop:terminal_tracking}.

\textbf{Method:}
\begin{enumerate}
  \item Produce at least two V3 artifacts (\texttt{terminal\_ovk\_scan}) from distinct models with different $\ell^\star$ (e.g., DeepSeek-V3 and Moonlight-16B).
  \item Bundle the V3 artifacts into a single V4 artifact (\texttt{terminal\_tracking}).
  \item Verify each embedded V3 artifact against \cref{prop:terminal_regime}, and verify that at least two distinct terminal depths are present.
\end{enumerate}

\textbf{Pass criteria:}
\begin{enumerate}
  \item All embedded V3 artifacts pass.
  \item At least two distinct \texttt{terminal\_moe\_layer} values are present.
\end{enumerate}

\textbf{Implementation:} \texttt{scripts/testD\_terminal\_tracking.py} + \texttt{scripts/verify\_routing\_geometry.py}\\
\textbf{Artifact:} JSON embedding V3 artifacts under \texttt{scans[]} and declaring \texttt{verification.min\_distinct\_terminals}.
\end{verification}

\begin{verification}[V5a: KL-forgetting edge dominance (open weights)]\label{vrf:kl_edge_dominance}
\textbf{Goal:} Verify \cref{prop:kl_edge_dominance}.

\textbf{Pre-registration.}
Record:
\begin{itemize}
  \item Family id, base checkpoint $\theta_0$, and descendant checkpoints $\Theta$.
  \item Domain set $\mathfrak{D}$ (canonical: \texttt{fineweb}, \texttt{code}) and window samplers.
  \item Edge set $\mathcal{E}$ (directed).
\end{itemize}

\textbf{Canonical pre-registered families/edges (paper runs).}
The concrete checkpoint identifiers are recorded verbatim in the produced artifact; the table below records the \emph{intended} family/edge structure:
\begin{center}
\begin{tabular}{llll}
\toprule
\textbf{Family} & \textbf{Base} $\theta_0$ & \textbf{Descendants} & \textbf{Edges $\mathcal{E}$} \\
\midrule
DeepSeek-V3 & V3-Base & V3, 0324, R1, R1-Zero &
(V3$\to$0324), (0324$\to$R1), (0324$\to$R1-Zero) \\
DeepSeek-V3.2 & V3.2-Base & V3.2, Speciale &
(V3.2$\to$Speciale) \\
Kimi-K2 & K2-Base & K2-Instruct, K2-Instruct-0905, K2-Thinking &
(K2-Instruct$\to$K2-Thinking), (K2-Instruct$\to$K2-Instruct-0905) \\
\bottomrule
\end{tabular}
\end{center}

\textbf{Method:}
\begin{enumerate}
  \item For each domain $d\in\mathfrak{D}$, sample $n\ge 200$ windows $w_i\sim\mathcal{D}_d$.
  \item For each checkpoint $\theta_j\in\Theta$, compute per-window $D(w_i;\theta_j,\theta_0)$ and per-window loss deltas $\mathrm{loss}_{\theta_j}(w_i)-\mathrm{loss}_{\theta_0}(w_i)$.
  \item For each edge $(i,j)\in\mathcal{E}$, bootstrap over windows to obtain CI95 for the drift and forgetting differences.
\end{enumerate}

\textbf{Pass criteria:}
\begin{enumerate}
  \item For all $d\in\mathfrak{D}$ and $(i,j)\in\mathcal{E}$, $\inf \mathrm{CI}_{0.95}(\widehat{D}_d(\theta_j)-\widehat{D}_d(\theta_i))>0$.
  \item For all $d\in\mathfrak{D}$ and $(i,j)\in\mathcal{E}$, $\inf \mathrm{CI}_{0.95}(\widehat{\mathcal{L}}_{\mathrm{forget},d}(\theta_j)-\widehat{\mathcal{L}}_{\mathrm{forget},d}(\theta_i))>0$.
\end{enumerate}

\textbf{Implementation:} \texttt{scripts/testE\_kl\_edge\_dominance.py}\\
\textbf{Artifact:} JSON storing per-window arrays for $D(w;\theta_j,\theta_0)$ and loss deltas for each checkpoint and each domain, plus declared $\mathcal{E}$; sufficient for independent re-bootstrap.\\
\textbf{Status:} IMPLEMENTED (verification runner: \texttt{scripts/verify\_routing\_geometry.py}).
\end{verification}

\begin{verification}[V5c: Entropy collapse (open weights, diagnostic)]\label{vrf:entropy_collapse}
\textbf{Goal:} Measure entropy/varentropy drift across a checkpoint family, and report deltas across pre-registered edges.

\textbf{Method:}
\begin{enumerate}
  \item For each domain $d\in\mathfrak{D}$, sample $n\ge 200$ teacher-forced windows $w_i\sim\mathcal{D}_d$.
  \item For each checkpoint $\theta_j$, compute per-window mean entropy $H(w_i;\theta_j)$ and varentropy $V(w_i;\theta_j)$ of the next-token distribution.
  \item For each declared edge $(i,j)$, report bootstrap CI95 for $\Delta H = \E[H(\theta_j)-H(\theta_i)]$ and similarly for $\Delta V$.
\end{enumerate}

\textbf{Implementation:} \texttt{scripts/testF\_entropy\_collapse.py}\\
\textbf{Artifact:} JSON storing per-window arrays for $H(w)$ and $V(w)$ for each checkpoint and domain, plus bootstrap params; sufficient for independent re-bootstrap.\\
\textbf{Status:} IMPLEMENTED (schema verified by \texttt{scripts/verify\_routing\_geometry.py}).
\end{verification}

\begin{verification}[V5b: KL-bounded adaptation (intervention)]\label{vrf:kl_bounded}
\textbf{Goal:} Verify \cref{prop:kl_bounded}.

\textbf{Pre-registration.}
Before training, record:
\begin{itemize}
  \item Frozen layer set $\mathcal{F}$ and trainable set $\mathcal{T}$.
  \item KL threshold $D_{\mathrm{max}} > 0$ and forgetting threshold $\mathcal{L}_{\mathrm{max}} > 0$.
  \item Evaluation distribution $\mathcal{D}_{\mathrm{eval}}$ and base distribution $\mathcal{D}_{\mathrm{base}}$.
  \item Comparison recipe (e.g., full fine-tune with $\mathcal{F}' = \emptyset$).
\end{itemize}

\textbf{Method:}
\begin{enumerate}
  \item Train model $\theta$ with frozen set $\mathcal{F}$.
  \item Train comparison model $\theta'$ with frozen set $\mathcal{F}'$ (fewer or no frozen layers).
  \item Sample $N \geq 1000$ examples from $\mathcal{D}_{\mathrm{eval}}$; compute $\hat{D}(\theta)$ and $\hat{D}(\theta')$.
  \item Sample $M \geq 1000$ examples from $\mathcal{D}_{\mathrm{base}}$; compute $\hat{\mathcal{L}}_{\mathrm{forget}}(\theta)$ and $\hat{\mathcal{L}}_{\mathrm{forget}}(\theta')$.
  \item Repeat for $K \geq 5$ training runs (varying seeds/checkpoints) to enable correlation analysis.
  \item Compute Spearman $\rho(\hat{D}, \hat{\mathcal{L}}_{\mathrm{forget}})$ across the $K$ runs; bootstrap for CI.
\end{enumerate}

\textbf{Pass criteria:}
\begin{enumerate}
  \item $\hat{D}(\theta) \leq D_{\mathrm{max}}$.
  \item $\hat{\mathcal{L}}_{\mathrm{forget}}(\theta) \leq \mathcal{L}_{\mathrm{max}}$.
  \item $\inf \mathrm{CI}_{0.95}(\rho) > 0$ (KL-forgetting correlation is significantly positive).
  \item $\hat{D}(\theta) < \hat{D}(\theta')$ and $\hat{\mathcal{L}}_{\mathrm{forget}}(\theta) < \hat{\mathcal{L}}_{\mathrm{forget}}(\theta')$ (freeze advantage).
\end{enumerate}

\textbf{Implementation:} \texttt{scripts/testE\_kl\_bounded\_adaptation.py}\\
\textbf{Artifact:} JSON per \texttt{docs/routing\_geometry\_artifacts.tex} with fields \texttt{frozen\_set}, \texttt{runs[].D\_hat}, \texttt{runs[].L\_forget\_hat}, \texttt{thresholds.\{D\_max,L\_max\}}, \texttt{summary.correlation.\{rho,ci95,K\}}, \texttt{baseline.\{D\_hat,L\_forget\_hat\}}, and \texttt{summary.freeze\_advantage}.\\
\textbf{Status:} UNIMPLEMENTED.
\end{verification}

\subsection{Cross-Validation: V2 $\wedge$ V3 Conjunction}\label{sec:crossval}

The verification tests are not independent.
V3 \emph{discovers} where the terminal interface regime occurs; V2 \emph{verifies} that overlap-compatibility holds at that location.
The conjunction explains why routing chaos at terminal does not cause output divergence.

\begin{requirement}[Terminal overlap-compatibility]\label{req:terminal_compat}
Let $\ell^\star$ be the terminal MoE layer identified by V3 (i.e., the layer where the dominant $\mathrm{ov}_k^{\mathrm{cf}}$ cliff occurs with bootstrap probability $\geq 0.95$).
The system satisfies \emph{terminal overlap-compatibility} if and only if:
\begin{enumerate}
  \item V3 passes: the terminal regime is localized at $\ell^\star$ with CI-verified dominance.
  \item V2 passes with $\mathcal{L}_{\mathrm{V2}} \supseteq \{\ell^\star\}$: overlap-compatibility holds at the terminal layer.
\end{enumerate}
\end{requirement}

\paragraph{Interpretation.}
If V3 passes but V2 fails at $\ell^\star$, then the terminal exhibits routing chaos \emph{without} overlap-compatibility---this would predict output instability and should be flagged as a potential failure mode.
If both pass, the system has a ``safe'' terminal interface: routing can be chaotic because adjacent experts are redundant.

\paragraph{Layer set selection.}
For a model with terminal layer $\ell^\star$ identified by V3:
\begin{itemize}
  \item \textbf{Terminal-only}: $\mathcal{L}_{\mathrm{V2}} = \{\ell^\star\}$ (minimum requirement).
  \item \textbf{Terminal + transition}: $\mathcal{L}_{\mathrm{V2}} = \{\ell^\star - 1, \ell^\star\}$ (tests whether overlap-compatibility emerges at the transition).
  \item \textbf{Mid-band check (canonical for Law 2)}: for DeepSeek V3 with $\ell^\star=60$, use $\mathcal{L}_{\mathrm{V2}}=\{30,40,50\}$.
  \item \textbf{Full depth scan}: $\mathcal{L}_{\mathrm{V2}} = \mathcal{L}$ (maps overlap-compatibility across depth; dense-only layers are outside scope, and the terminal layer is permitted to differ from mid-band).
\end{itemize}

\begin{tcolorbox}[colback=blue!3!white,colframe=blue!55!black,title=Traceability Matrix]
\centering
\begin{tabular}{lllll}
\toprule
\textbf{Property} & \textbf{Test} & \textbf{Script} & \textbf{Artifact} & \textbf{Status} \\
\midrule
\cref{prop:boundary_amp} & V1 & \texttt{traj\_boundary\_amplification\_ondist\_topk.py} & JSON ($F(q)$, deciles) & IMPL \\
\cref{prop:behavior_compression} & V1b & \texttt{traj\_behavior\_compression\_ondist\_topk.py} & JSON ($F_{\mathrm{route}}$, $F_{\mathrm{beh}}$, CI) & IMPL \\
\cref{prop:overlap_compat} & V2 & \texttt{testB\_chart\_compatibility.py} & JSON ($\kappa$ medians, CIs) & IMPL \\
\cref{prop:terminal_regime} & V3 & \texttt{testC\_terminal\_ovk\_scan.py} & JSON/TSV (ov$_k$, CI) & IMPL \\
\cref{prop:terminal_tracking} & V4 & \texttt{testD\_terminal\_tracking.py} & JSON (embedded V3 scans) & IMPL \\
\cref{prop:kl_edge_dominance} & V5a & \texttt{testE\_kl\_edge\_dominance.py} & JSON ($\hat{D}$, $\hat{\mathcal{L}}$; edges) & IMPL \\
\textit{(diagnostic)} & V5c & \texttt{testF\_entropy\_collapse.py} & JSON ($\hat{H}$, $\hat{V}$; edges) & IMPL \\
\cref{prop:kl_bounded} & V5b & \texttt{testE\_kl\_bounded\_adaptation.py} & JSON ($\hat{D}$, $\hat{\mathcal{L}}$, $\rho$) & UNIMPL \\
\bottomrule
\end{tabular}
\end{tcolorbox}

\paragraph{Note on reproducibility.}
All tests must record (i) gate semantics profile $\mathcal{S}$ (\cref{def:gate_semantics}), (ii) score precision (fp32 per \cref{ax:fp32}), (iii) the window selection procedure (raw text windows and seed), and (iv) the bootstrap protocol per \cref{sec:bootstrap}.

\paragraph{Verification runner.}
The repository provides a minimal verifier \texttt{scripts/verify\_routing\_geometry.py} that checks produced JSON artifacts against the pass/fail criteria in this specification.

\end{document}
