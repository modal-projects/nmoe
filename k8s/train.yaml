apiVersion: batch/v1
kind: Job
metadata:
  name: nmoe-train-moonlet
  labels:
    app: nmoe
    role: train
    preset: moonlet
spec:
  template:
    metadata:
      labels:
        app: nmoe
        role: train
        preset: moonlet
    spec:
      restartPolicy: Never
      runtimeClassName: nvidia
      tolerations:
        - key: nvidia.com/gpu
          value: "true"
          effect: NoSchedule
      containers:
        - name: train
          image: xjdr/nmoe_train:latest
          imagePullPolicy: Always
          workingDir: /workspace/nmoe
          command: ["/bin/bash", "-lc"]
          args:
            - |
              set -euo pipefail
              echo "=== starting nmoe single-GPU training (moonlet) ==="
              /workspace/nmoe/.venv/bin/python -m nmoe.train configs/moonlet.toml
          env:
            - name: PYTORCH_CUDA_ALLOC_CONF
              value: "expandable_segments:True"
            - name: NCCL_DEBUG
              value: "WARN"
            - name: NCCL_IB_DISABLE
              value: "1"
            - name: NCCL_P2P_DISABLE
              value: "0"
            - name: NCCL_P2P_LEVEL
              value: "NVL"
            - name: CUDA_DEVICE_MAX_CONNECTIONS
              value: "1"
          resources:
            requests:
              nvidia.com/gpu: 1
            limits:
              nvidia.com/gpu: 1
          volumeMounts:
            - name: data
              mountPath: /data
            - name: dshm
              mountPath: /dev/shm
      volumes:
        - name: data
          persistentVolumeClaim:
            claimName: nmoe-data
        - name: dshm
          emptyDir:
            medium: Memory
            sizeLimit: 16Gi
