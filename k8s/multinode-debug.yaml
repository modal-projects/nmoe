apiVersion: batch/v1
kind: Job
metadata:
  name: nmoe-multinode-debug
  labels:
    app: nmoe
    stage: multinode-debug
spec:
  completions: 2
  parallelism: 2
  completionMode: Indexed
  template:
    metadata:
      labels:
        app: nmoe
        stage: multinode-debug
    spec:
      restartPolicy: Never
      hostNetwork: true
      dnsPolicy: ClusterFirstWithHostNet
      runtimeClassName: nvidia
      tolerations:
        - key: nvidia.com/gpu
          value: "true"
          effect: NoSchedule
      # Anti-affinity to ensure pods land on different nodes
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchLabels:
                  app: nmoe
                  stage: multinode-debug
              topologyKey: kubernetes.io/hostname
      containers:
        - name: nmoe
          image: xjdr/nmoe_dist:latest
          imagePullPolicy: Always
          command: ["/bin/bash"]
          args:
            - -c
            - |
              cd /workspace/nmoe

              # hostNetwork pods may not get a hostname->IP mapping in /etc/hosts.
              # torchrun/c10d sometimes resolves `hostname`; make it deterministic.
              echo "${HOST_IP} $(hostname)" >> /etc/hosts

              # Get job index from k8s
              JOB_INDEX=${JOB_COMPLETION_INDEX:-0}

              echo "=== nmoe Multi-Node Debug Container Ready ==="
              echo "Node: $(hostname)"
              echo "Job Index: $JOB_INDEX"
              echo "Privileged: true (ncu/nsys enabled)"
              echo "Network: host"
              echo ""

              # Export environment for multi-node
              export MASTER_ADDR="${MASTER_ADDR:-$HOST_IP}"
              export MASTER_PORT=29500
              export WORLD_SIZE=2
              export RANK=$JOB_INDEX
              export LOCAL_WORLD_SIZE=8
              export LOCAL_RANK=0

              echo "MASTER_ADDR: $MASTER_ADDR"
              echo "HOST_IP: $HOST_IP"
              echo "POD_IP: $POD_IP"
              echo "POD_NAME: $POD_NAME"
              echo "NODE_NAME: $NODE_NAME"
              echo "RANK: $RANK"
              echo ""
              echo "Use 'kubectl exec -it <pod-name> -- bash' to access"
              echo ""

              # Loop indefinitely
              while true; do sleep 3600; done
          env:
            - name: HOST_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: NODE_NAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            - name: PYTORCH_CUDA_ALLOC_CONF
              value: "expandable_segments:True"
            - name: GLOO_SOCKET_IFNAME
              value: "eno1"
            - name: NCCL_DEBUG
              value: "INFO"
            - name: NCCL_SOCKET_FAMILY
              value: "AF_INET"
            - name: NCCL_SOCKET_IFNAME
              value: "eno1"
            - name: NCCL_IB_DISABLE
              value: "0"
            - name: NCCL_NET_GDR_LEVEL
              value: "5"
            - name: NCCL_IB_GID_INDEX
              value: "3"
            - name: NVSHMEM_REMOTE_TRANSPORT
              value: "ibgda"
            - name: NVSHMEM_IB_ENABLE_IBGDA
              value: "1"
            - name: NVSHMEM_DISABLE_CUDA_VMM
              value: "1"
            - name: NVSHMEM_DISABLE_NVLS
              value: "1"
            - name: NVSHMEM_DISABLE_MNNVL
              value: "1"
            - name: NVSHMEM_DISABLE_P2P
              value: "0"
            - name: NVSHMEM_BOOTSTRAP_UID_SOCK_FAMILY
              value: "AF_INET"
            - name: NVSHMEM_BOOTSTRAP_UID_SOCK_IFNAME
              value: "eno1"
            - name: NVSHMEM_DEBUG
              value: "WARN"
            - name: NVSHMEM_MAX_TEAMS
              value: "7"
            - name: NVSHMEM_CUMEM_GRANULARITY
              value: "536870912"
            - name: NVSHMEM_SYMMETRIC_SIZE
              value: "16G"
          securityContext:
            privileged: true
            capabilities:
              add:
                - SYS_ADMIN
                - SYS_PTRACE
                - IPC_LOCK
          volumeMounts:
            - name: data
              mountPath: /data
            - name: dshm
              mountPath: /dev/shm
          resources:
            requests:
              nvidia.com/gpu: 8
            limits:
              nvidia.com/gpu: 8
      volumes:
        - name: data
          persistentVolumeClaim:
            claimName: nmoe-data
        - name: dshm
          emptyDir:
            medium: Memory
            sizeLimit: 64Gi
